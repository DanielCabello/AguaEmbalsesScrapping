{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evolución de las reservas hídricas de los embalses de España"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB SCRAPPING DEL SITIO WEB EMBALSES.NET\n",
    "\n",
    "# Se importan las librerías que se van a utilizar\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 1. Obtención de los links a los datos de los embalses para cada cuenca\n",
    "page = requests.get(\"https://www.embalses.net/cuenca-17-cantabrico-occidental.html\")\n",
    "soup = BeautifulSoup(page.content)\n",
    "ca = soup.body.find_all(class_='index_bodysecLisT2_list')\n",
    "\n",
    "# 1.a Se obtiene todos los links de la sección que hemos extraido\n",
    "link = []\n",
    "for k in soup.find_all('a'):\n",
    "    link.append(k.get('href'))\n",
    "\n",
    "# 1.b Se filtran los links que nos interesan (el de las cuencas) y se almacenan en una lista\n",
    "link1=[]\n",
    "for i in link:\n",
    "    if re.search('www.embalses.net/cuenca-', i):\n",
    "        link1.append(i)\n",
    "\n",
    "# 2. Extracción de los datos de cada embalse para todas las cuencas\n",
    "\n",
    "# 2.a Se crea un dataframe vacío en el que se van a ir almacenando los datos\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "# 2.b Se crea un bucle que extrae los datos de los embalses ubicados en cada link (cuenca) y los almacena en un dataframe\n",
    "for i in link1:\n",
    "    # \n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    a = soup.body.section.div.find_all(class_='SeccionCentral_Caja')[0]\n",
    "\n",
    "    # Se obtiene el nombre de la cuenca y se almacena en una variable\n",
    "    cuenca = soup.find(class_='SeccionCentral_TituloTexto').text\n",
    "    cuenca = cuenca.replace('Cuenca: ', '')\n",
    "    \n",
    "    #Se obtiene la fecha del agua embalsada\n",
    "    a = soup.body.section.div.find_all(class_='SeccionCentral_Caja')[0]\n",
    "    fecha = a.find(class_='Campo').text\n",
    "    fecha = fecha.replace('Agua embalsada (','')\n",
    "    fecha = fecha.replace('):', '')\n",
    "    \n",
    "    # Se extraen los nombres de los campos y se almacenan en una lista\n",
    "    b = soup.body.section.div.find_all(class_='SeccionCentral_Caja')[1]\n",
    "    tupa = []\n",
    "    for i in b.tr.find_all('td'):\n",
    "        tupa.append(i.get_text())\n",
    "\n",
    "\n",
    "    # Se extraen los valores de los embalses (pantano, capacidad, embalsada y variación) y se almacenan en una lista\n",
    "    tupa1 = []\n",
    "    for i in b.find_all(class_='ResultadoCampo'):\n",
    "        for j in i.find_all('td'):\n",
    "            tupa1.append(j.get_text())\n",
    "\n",
    "    # Quitar espacio en blanco y \"\\n\"\n",
    "    tupa1 = [words.replace('\\n', '') for words in tupa1]\n",
    "    tupa1 = [words.strip() for words in tupa1]\n",
    "\n",
    "    \n",
    "    # la lista tupa1 se transforma en una lista de listas (una matriz)\n",
    "    recorrer = len(tupa)\n",
    "    tupa2 = [tupa1[i:i+recorrer] for i in range(0, len(tupa1), recorrer)]\n",
    "    \n",
    "\n",
    "    # Se transforma la lista de listas con los valores de los embalses en un dataframe\n",
    "    df = pd.DataFrame(tupa2,columns = tupa)\n",
    "    \n",
    "    # se añade dos nuevos campos al dataframe: nombre de la cuenca y fecha de la actualización de los datos\n",
    "    df['Cuenca'] = cuenca\n",
    "    df['fecha'] = fecha\n",
    "    df2 = pd.concat([df2, df], axis=0)\n",
    "    \n",
    "\n",
    "# 2.c Se genera un archivo csv a partir del dataframe df2\n",
    "\n",
    "df2.to_csv(r'D:\\reservas_embalses_'+ fecha +'.csv', index= False, sep = ';')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
